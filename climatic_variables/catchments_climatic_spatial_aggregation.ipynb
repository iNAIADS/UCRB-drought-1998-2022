{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvN62JXphEUT"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from copy import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptRRdJxGhN2P"
   },
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project='catchments-climate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs shapefiles from https://www.geoplatform.gov/metadata/673067aa-83e8-4e4a-9f02-3f55ed028b72\n",
    "\n",
    "catchments_gages = gpd.read_file('boundaries-shapefiles-by-aggeco/gages_basins_conus.shp', dtype={'GAGE_ID': 'str'})\n",
    "catchments_gages.set_crs(epsg=4269, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"STAID_for_drought.json\", 'r') as file:\n",
    "    STAID_for_drought = json.load(file)\n",
    "    \n",
    "catchments_gdb = catchments_gages[catchments_gages.GAGE_ID.isin(STAID_for_drought)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAcw8xzAhysy"
   },
   "outputs": [],
   "source": [
    "def make_spatial_aggregation(img, agg_funct=ee.Reducer.mean()):\n",
    "  \"\"\"\n",
    "  Function that spatially aggregates all the variables\n",
    "  PARAMS:\n",
    "    img (ee.ImageCollection): image collection containing the variables to be spatially aggregated\n",
    "  OPTIONAL PARAMS:\n",
    "    agg_funct (ee.Reducer function): funtion to be used as spatial aggregator. Default: ee.Reducer.mean()\n",
    "  RETURNS:\n",
    "    img (ee.ImageCollection): image collection containing the spatially aggregated variables\n",
    "  \"\"\"\n",
    "\n",
    "  img = ee.Image(img)\n",
    "  date = img.get('system:time_start')\n",
    "  variables_dict = {\"date_agg\": date}\n",
    "  for variable in variables_:\n",
    "    variable_band = img.select(variable)\n",
    "    stats = variable_band.reduceRegion(reducer=agg_funct, geometry=roi, scale=30, bestEffort=True)\n",
    "    variables_dict[variable+\"_agg\"] = stats.get(variable)\n",
    "  return img.set(variables_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEJak0izlAY1"
   },
   "outputs": [],
   "source": [
    "def wrapper_roi(dataset,\n",
    "            variables_,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            roi,\n",
    "            roi_name,\n",
    "            model=None):\n",
    "  print(variables_)\n",
    "# Load the collection from the Climatic Model\n",
    "# Filter by date and roi\n",
    "  if model is not None:\n",
    "    collection = ee.ImageCollection(dataset) \\\n",
    "              .filter(ee.Filter.eq('model', model)) \\\n",
    "              .filterDate(start_date, end_date) \\\n",
    "              .filterBounds(roi).select(variables_[0])\n",
    "\n",
    "  else:\n",
    "    collection = ee.ImageCollection(dataset) \\\n",
    "                .filterDate(start_date, end_date) \\\n",
    "                .filterBounds(roi).select(variables_[0])\n",
    "\n",
    "\n",
    "  # Sort the filtered collection by date in ascending order\n",
    "  sorted_collection = collection.sort('system:time_start')\n",
    "\n",
    "  # Map the function to the image collection\n",
    "  sorted_collection_changed = sorted_collection.map(make_spatial_aggregation)\n",
    "\n",
    "  # Extract dates and variables as numpy array\n",
    "  dates_array = sorted_collection_changed.aggregate_array('date_agg')\n",
    "  variable_arrays = [sorted_collection_changed.aggregate_array(variable+'_agg') for variable in variables_]\n",
    "\n",
    "  # Convert the array to a list using getInfo()\n",
    "  dates_list = dates_array.getInfo()\n",
    "  variable_lists = [variable_array.getInfo() for variable_array in variable_arrays]\n",
    "\n",
    "  # Convert dates into strings\n",
    "  string_timestamps = [datetime.datetime.utcfromtimestamp(int(date_str) // 1000) for date_str in dates_list]\n",
    "\n",
    "  # Create a DataFrame to store the data\n",
    "  data = dict(zip(variables_, variable_lists))\n",
    "  data['date_agg'] = string_timestamps\n",
    "  df = pd.DataFrame(data, columns=[\"date_agg\"]+variables_)\n",
    "\n",
    "  # Return DataFrame\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCagxh22nCiZ"
   },
   "outputs": [],
   "source": [
    "def make_ee_geometry(gdb, code_name, code_id):\n",
    "  catchment_gdb = gdb[gdb[code_name]==code_id].iloc[0]\n",
    "  catchment_geometry_gdb = catchment_gdb.geometry\n",
    "  if catchment_geometry_gdb.geom_type == 'MultiPolygon':\n",
    "    catchment_coords = [[list(polygon.exterior.coords)] for polygon in catchment_geometry_gdb.geoms]\n",
    "  elif catchment_geometry_gdb.geom_type == 'Polygon':\n",
    "    catchment_coords = [[list(catchment_geometry_gdb.exterior.coords)]]\n",
    "  else:\n",
    "    raise ValueError('Geometry is expected to be either a Polygon or a MultiPolygon')\n",
    "  return ee.Geometry.MultiPolygon(catchment_coords)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Q3YS7JRBieb3",
    "outputId": "683a3d45-1ae4-42eb-a5b0-4e684049924d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define start and end dates\n",
    "start_date = '1980-01-01'\n",
    "end_date = '2024-10-01'\n",
    "\n",
    "dataset = 'OREGONSTATE/PRISM/AN81m'\n",
    "variables = ['tmean', 'ppt']\n",
    "model = None\n",
    "\n",
    "code_name=\"GAGE_ID\"\n",
    "roi_names = catchments_gdb[code_name].values\n",
    "\n",
    "for j,variable in enumerate(variables):\n",
    "    for i,roi_name in enumerate(roi_names):\n",
    "      print(i, roi_name, variable)\n",
    "\n",
    "      roi = make_ee_geometry(catchments_gdb, code_name, roi_name)\n",
    "      variables_ = variables[j:j+1]\n",
    "      df = wrapper_roi(dataset, variables_, start_date, end_date, roi, roi_name, model=model)\n",
    "      if i==0 and j==0:\n",
    "        df.rename(columns={variable: str(roi_name)+\"|\"+variable for variable in variables_}, inplace=True)\n",
    "        df_all = copy(df)\n",
    "      else:\n",
    "        for variable in variables_:\n",
    "            df_all[str(roi_name)+\"|\"+variable] = df[variable].values\n",
    "\n",
    "df_all.to_csv(f'{dataset.replace(\"/\",\"-\")}_{\"_\".join(variables)}_{start_date}_{end_date}.csv.gz', index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
